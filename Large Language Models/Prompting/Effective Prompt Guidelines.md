From the paper: [LLMs for CSS](https://aclanthology.org/2024.cl-1.8.pdf)

| Effective Prompt Guideline                                                                                                                                                                                                  | Reference               | Guideline Example                                                                                                                                    |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| When the answer is categorical, enumerate options as alphabetical mltiple-choice so that the output is simply the highest-probability token ('A', 'B').                                                                     | Hendrycks et al. (2021) | {\$CONTEXT}<br><br>Which of the following describes the above news headline?<br>A: Misinformation<br>B: Trustworthy<br><br>{\$CONSTRAINT}            |
| Each option should be separated by a new line to resemble the natural format of online multiple choice questions. More natural prompts will elicit more regular behaviour.                                                  | Inverse Scaling Prize   | see above.                                                                                                                                           |
| To promote instruction-following, give instructions after the context is provided; then explicitly state and constraints. Recent and repeated text has a greater effect on LLM generations due to common attention patterns | Child et al. (2019)     | {\$CONTEXT}<br>{\$QUESTION}<br><br>Constraint: Even if you are uncertain, you **must pick either "True", or "False"** without using any other words. |
| Clarify the expected output in the case of uncertainty. Uncertain models may use default phrases like "I don't know," and clarifying contraints force the model to answer.                                                  | No reference            | see above.                                                                                                                                           |
| When the answer should contain multiple pieces of information, request responses in JSON format. This leverages LLM's familiarity with code to provide an output structure that is more easily parsed                       | MiniChain Library       | {\$CONTEXT}<br>{\$QUESTION}<br><br>JSON Output:                                                                                                      |
|                                                                                                                                                                                                                             |                         |                                                                                                                                                      |
